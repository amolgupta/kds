{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%use spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Read a file. This file contains the landing page of kotlin data science page.\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "var textFile : RDD<String> = SparkSession.builder()\n",
    "            .orCreate.sparkContext()\n",
    "            .textFile(\"../data/data-science.md\",1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actions on a single RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// line count\n",
    "textFile.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# Kotlin for Data Science"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read first line\n",
    "textFile.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Kotlin-jupyter](https://github.com/Kotlin/kotlin-jupyter) is an open source project that brings Kotlin, ![Kotlin in Jupyter notebook]({{ url_for('asset', path='images/landing/data-science/kotlin-jupyter-kernel.png')}}), Check out Kotlin kernel's [GitHub repo](https://github.com/Kotlin/kotlin-jupyter) for installation, ![Kotlin in Zeppelin notebook]({{ url_for('asset', path='images/landing/data-science/kotlin-zeppelin-interpreter.png')}}), * [kotlin-statistics](https://github.com/thomasnield/kotlin-statistics) is a library providing extension functions for, * [Smile](https://github.com/haifengl/smile) - a comprehensive machine learning, natural language processing, linear algebra, graph, interpolation, and visualization system. Besides Java API, Smile also provides a functional [Kotlin API](http://haifengl.github.io/api/kotlin/smile-kotlin/index.html) along with Scala and Clojure API., [**Kotlin Data Science Resources**](https://github.com/thomasnield/kotlin-data-science-resources) digest from Thomas Nield.]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Show all lines with workd \"kotlin\"\n",
    "textFile.toJavaRDD().filter{ it.contains(\"kotlin\")}.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark loads the file lazily(when first action is called) and does not persist. Each time we call an action like above, spark loads the file. To persist the file we call the `persist` action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "../data/data-science.md MapPartitionsRDD[11] at textFile at <unknown>:0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[# KOTLIN FOR DATA SCIENCE, , FROM BUILDING DATA PIPELINES TO PRODUCTIONIZING MACHINE LEARNING MODELS, KOTLIN CAN BE A GREAT CHOICE FOR, WORKING WITH DATA:, * KOTLIN IS CONCISE, READABLE AND EASY TO LEARN.]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Mapper\n",
    "textFile.toJavaRDD().map{ it.toUpperCase()}.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actions on 2 RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Notebooks such as [Jupyter Notebook](https://jupyter.org/) and [Apache Zeppelin](https://zeppelin.apache.org/) provide convenient tools for data visualization and, The ecosystem of libraries for data-related tasks created by the Kotlin community is rapidly expanding., ### Kotlin libraries, streaming operations, a wrapper around [commons-math](http://commons.apache.org/proper/commons-math/) and, Lets-Plot is multiplatform and can be used not only with JVM, but also with JS and Python., , , ]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Run a union and print first 2 lines\n",
    "val kotlinLines = textFile.toJavaRDD().filter{ it.contains(\"kotlin\")}.collect()\n",
    "val dataLines = textFile.toJavaRDD().filter{ it.contains(\"data\")}.collect()\n",
    "// Take few items as the complete set may be too big\n",
    "dataLines.union(kotlinLines).take(2)\n",
    "\n",
    "// Flatmap\n",
    "textFile.toJavaRDD().flatMap { it -> (it.split(\" \").iterator()) }.take(10)\n",
    "\n",
    "// See a data sample. Shows 10% os the total dataset\n",
    "textFile.toJavaRDD().sample(false,0.1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "7\n",
      "22\n",
      "22\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "// Some common actions on RDD\n",
    "println(dataLines.count())\n",
    "println(kotlinLines.count())\n",
    "println(dataLines.union(kotlinLines).count())\n",
    "println(dataLines.union(kotlinLines).distinct().count())\n",
    "println(dataLines.subtract(kotlinLines).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[From building data pipelines to productionizing machine learning models, Kotlin can be a great choice for, working with data:]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLines.union(kotlinLines).take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word count example\n",
    "This uses simple map reduce functions to count the number of words in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([Ljava.lang.String;@50302a6a,1), ([Ljava.lang.String;@4ea8f3fb,1), ([Ljava.lang.String;@6d70f503,1), ([Ljava.lang.String;@279c30c9,1), ([Ljava.lang.String;@76ae2d2a,1)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.Tuple2\n",
    "\n",
    "        textFile.toJavaRDD().flatMap {\n",
    "            listOf(it.split(\" \").toTypedArray())\n",
    "                .iterator()\n",
    "        }.mapToPair { word -> Tuple2(word, 1) }\n",
    "            .reduceByKey { a, b -> a + b }\n",
    "            .collect().take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": "kt",
   "name": "kotlin"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
